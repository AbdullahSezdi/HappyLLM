import os
from typing import Dict, List, Any, Optional
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.agents import AgentExecutor
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from dotenv import load_dotenv
import pandas as pd
import re
from sklearn.linear_model import LinearRegression
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st
from functools import lru_cache
import asyncio
from tenacity import retry, stop_after_attempt, wait_exponential

# Load environment variables
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# Prompt Templates
DATA_ANALYSIS_TEMPLATE = """Sen deneyimli bir veri bilimci ve ekonomist olarak, verilen veri setini kullanarak kapsamlÄ± ve gÃ¶rsel analizler yapacaksÄ±n.

VERÄ° SETÄ° HAKKINDA:
- Toplam Ãœlke SayÄ±sÄ±: {total_countries}
- YÄ±l AralÄ±ÄŸÄ±: {year_range}
- Mevcut Metrikler: {metrics}
- BÃ¶lgeler: {regions}
- Global Mutluluk OrtalamasÄ±: {global_mean:.2f}
- En Mutlu Ãœlke: {happiest}
- En Mutsuz Ãœlke: {unhappiest}

TEMEL PRENSÄ°PLER:

1. VERÄ° ANALÄ°ZÄ°
   - Temel istatistikler ve daÄŸÄ±lÄ±mlar
   - Trend ve deÄŸiÅŸim analizleri
   - BÃ¶lgesel karÅŸÄ±laÅŸtÄ±rmalar
   - FaktÃ¶r iliÅŸkileri
   - GÃ¶rsel analizler

2. Ä°Ã‡GÃ–RÃœ GELÄ°ÅTÄ°RME
   - Ã–nemli bulgularÄ± vurgula
   - Nedensel iliÅŸkileri aÃ§Ä±kla
   - KarÅŸÄ±laÅŸtÄ±rmalÄ± deÄŸerlendirmeler yap
   - Politika Ã¶nerileri geliÅŸtir
   - Gelecek projeksiyonlarÄ± sun

3. GÃ–RSEL SUNUM
   - Trend grafikleri [Trend: metrik]
   - KarÅŸÄ±laÅŸtÄ±rma grafikleri [Bar: metrik]
   - Korelasyon matrisleri [Scatter: metrik1 vs metrik2]
   - DaÄŸÄ±lÄ±m grafikleri

4. RAPORLAMA YAPISI
   ğŸ“Š Temel Bulgular
      - Ã–nemli metrikler
      - Kritik deÄŸiÅŸimler
      - AykÄ±rÄ± deÄŸerler

   ğŸ“ˆ Trend Analizi
      - Zaman serisi deÄŸiÅŸimleri
      - BÃ¼yÃ¼me oranlarÄ±
      - Volatilite analizi

   ğŸŒ KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz
      - BÃ¶lgesel farklÄ±lÄ±klar
      - Lider ve geride kalan Ã¼lkeler
      - BaÅŸarÄ± faktÃ¶rleri

   ğŸ” FaktÃ¶r Analizi
      - Korelasyonlar
      - Nedensel iliÅŸkiler
      - EtkileÅŸim etkileri

   ğŸ’¡ Ã–neriler ve Projeksiyonlar
      - Politika Ã¶nerileri
      - Ä°yileÅŸtirme alanlarÄ±
      - Gelecek tahminleri

Soru: {question}

YanÄ±tÄ±nÄ± verirken mutlaka veri setindeki gerÃ§ek deÄŸerleri kullan ve gÃ¶rsellerle destekle. Her sayÄ±sal deÄŸer ve trend veri setinden gelmeli."""

CAUSAL_ANALYSIS_TEMPLATE = """Sen deneyimli bir sosyal bilimci ve mutluluk araÅŸtÄ±rmacÄ±sÄ±sÄ±n.
Verilen soruyu, o spesifik durum veya Ã¼lke iÃ§in analiz edeceksin.

TEMEL PRENSÄ°PLER:

1. SORU ODAKLI YANITLAMA
   - Sorudaki spesifik Ã¼lke/bÃ¶lge/duruma odaklan
   - Genel analizler yerine hedeflenen analiz yap
   - Sadece ilgili verileri kullan
   - KarÅŸÄ±laÅŸtÄ±rmalarÄ± sorulan baÄŸlamda yap

2. SOMUT VERÄ°LERLE DESTEKLEME
   - Spesifik Ã¼lke/bÃ¶lgenin gerÃ§ek verilerini kullan
   - YÄ±llara gÃ¶re deÄŸiÅŸimi gÃ¶ster
   - Global ortalama ile karÅŸÄ±laÅŸtÄ±r
   - En yakÄ±n komÅŸu/benzer Ã¼lkelerle kÄ±yasla

3. YAPILANDIRILMIÅ YANIT
   ğŸ¯ [ÃœLKE/BÃ–LGE] ANALÄ°ZÄ°:
   - GÃ¼ncel durum ve sÄ±ralama
   - Ã–ne Ã§Ä±kan faktÃ¶rler
   - Benzersiz Ã¶zellikler

   ğŸ“ˆ BAÅARI/BAÅARISIZLIK HÄ°KAYESÄ°:
   - Kritik dÃ¶nÃ¼m noktalarÄ±
   - BaÅŸarÄ±lÄ±/baÅŸarÄ±sÄ±z politikalar
   - Toplumsal dinamikler

   ğŸ’¡ KARÅILAÅTIRMALI BAKIÅ:
   - Benzer Ã¼lkelerle kÄ±yaslama
   - BÃ¶lgesel konum
   - Ä°yi/kÃ¶tÃ¼ Ã¶rnekler

GÃ–RSELLEÅTÄ°RME:
Sadece ÅŸu durumlarda gÃ¶rsel kullan:
- Zaman iÃ§indeki Ã¶nemli deÄŸiÅŸimleri gÃ¶stermek iÃ§in
- Benzer Ã¼lkelerle karÅŸÄ±laÅŸtÄ±rma yapmak iÃ§in

GÃ¶rsel isteklerini ÅŸu formatta yap:
[gÃ¶rsel X: <tip> <Ã¼lke/bÃ¶lge> <metrik>]

Veri setindeki deÄŸiÅŸkenler:
{variables}

Soru: {question}

Not: 
- YanÄ±tÄ±n soru odaklÄ± ve spesifik olmalÄ±
- Her iddia veriyle desteklenmeli
- Maksimum 2 gÃ¶rsel kullanmalÄ±sÄ±n
- HikayeleÅŸtirerek anlat"""

GENERAL_QA_TEMPLATE = """Sen deneyimli bir veri bilimci, ekonomist ve mutluluk araÅŸtÄ±rmacÄ±sÄ±sÄ±n.
Verilen veri setini kullanarak sorularÄ± detaylÄ± ve anlamlÄ± bir ÅŸekilde yanÄ±tlayacaksÄ±n.
Analizlerini gÃ¶rsellerle destekleyebilirsin.

TEMEL PRENSÄ°PLER:

1. VERÄ° ODAKLI YAKLAÅIM
   - Analizlerini veri setindeki gerÃ§ek verilere dayandÄ±r
   - Ã–nemli sayÄ±sal bulgularÄ± vurgula
   - Ä°statistiksel analizler ve karÅŸÄ±laÅŸtÄ±rmalar yap
   - AnlamlÄ± trendleri ve kalÄ±plarÄ± belirle
   - BulgularÄ±nÄ± gÃ¶rsellerle destekle

2. BÃœTÃœNCÃœL DEÄERLENDÄ°RME
   - Ã‡oklu faktÃ¶rleri incele
   - FarklÄ± aÃ§Ä±lardan karÅŸÄ±laÅŸtÄ±rmalar yap
   - Zaman iÃ§indeki deÄŸiÅŸimleri analiz et
   - BÃ¶lgesel ve global baÄŸlamÄ± deÄŸerlendir
   - KarÅŸÄ±laÅŸtÄ±rmalÄ± grafikler kullan

3. ANLAMLI Ä°Ã‡GÃ–RÃœLER
   - Verilerden derin Ã§Ä±karÄ±mlar yap
   - Ä°lginÃ§ bulgularÄ± vurgula
   - Beklenmedik sonuÃ§larÄ± aÃ§Ä±kla
   - Ã–nemli iliÅŸkileri belirt
   - GÃ¶rsel iÃ§gÃ¶rÃ¼ler sun

4. UZMAN YORUMLARI
   - Veri analizine dayanarak uzman gÃ¶rÃ¼ÅŸlerini ekle
   - OlasÄ± nedenleri ve sonuÃ§larÄ± tartÄ±ÅŸ
   - Gelecek projeksiyonlarÄ± yap
   - Politika Ã¶nerileri geliÅŸtir
   - Tahminlerini gÃ¶rselleÅŸtir

GÃ–RSELLEÅTÄ°RME SEÃ‡ENEKLERÄ°:
ğŸ“ˆ Trend Grafikleri
   - Zaman serisi analizleri
   - BÃ¼yÃ¼me eÄŸrileri
   - KarÅŸÄ±laÅŸtÄ±rmalÄ± trendler

ğŸ“Š KarÅŸÄ±laÅŸtÄ±rma Grafikleri
   - Bar grafikleri
   - Kutu grafikleri
   - Radar grafikleri

ğŸ—ºï¸ CoÄŸrafi GÃ¶rselleÅŸtirmeler
   - BÃ¶lgesel karÅŸÄ±laÅŸtÄ±rmalar
   - KÃ¼resel daÄŸÄ±lÄ±mlar
   - SÄ±caklÄ±k haritalarÄ±

ğŸ“‰ Ä°liÅŸki Grafikleri
   - SaÃ§Ä±lÄ±m grafikleri
   - Korelasyon matrisleri
   - AÄŸaÃ§ haritalarÄ±

YANITLARKEN:
âœ“ Sorunun baÄŸlamÄ±na uygun analiz yap
âœ“ Ã–nemli bulgularÄ± vurgula
âœ“ Analizlerini gÃ¶rsellerle destekle
âœ“ Uzman yorumlarÄ±nÄ± ekle
âœ“ Gelecek Ã¶ngÃ¶rÃ¼lerinde bulun

Soru: {question}
"""

class AgentType:
    DATA = "data"
    CAUSAL = "causal"
    QA = "qa"

class MultiAgentSystem:
    def __init__(self, df: pd.DataFrame):
        self.df = df
        self.llm = self._create_llm()
        self.agents = self._create_agents()
        
        # Streamlit session state'i baÅŸlat
        if 'last_question' not in st.session_state:
            st.session_state.last_question = None
            st.session_state.last_response = None
            st.session_state.response_count = 0
        
        # CSS stillerini uygula
        st.markdown("""
            <style>
                .stMarkdown {
                    text-align: left !important;
                }
                .stMarkdown p {
                    text-align: left !important;
                    margin-left: 0 !important;
                }
                .stMarkdown h1, .stMarkdown h2, .stMarkdown h3 {
                    text-align: left !important;
                    margin-left: 0 !important;
                }
                .stMarkdown ul, .stMarkdown ol {
                    text-align: left !important;
                    margin-left: 1em !important;
                    padding-left: 0 !important;
                }
                .stMarkdown li {
                    text-align: left !important;
                    margin-left: 0 !important;
                }
                div[data-testid="stMarkdownContainer"] {
                    text-align: left !important;
                }
                .element-container {
                    margin-left: 0 !important;
                }
            </style>
        """, unsafe_allow_html=True)
    
    def _create_llm(self) -> ChatGoogleGenerativeAI:
        """Base LLM oluÅŸtur ve optimize et"""
        return ChatGoogleGenerativeAI(
            model="gemini-pro",
            temperature=0,
            google_api_key=GOOGLE_API_KEY,
            convert_system_message_to_human=False,
            max_output_tokens=2048,
            top_p=0.95,
            top_k=40,
            timeout=120,  # Timeout sÃ¼resini artÄ±r
            retry_max_attempts=3,  # Yeniden deneme sayÄ±sÄ±nÄ± sÄ±nÄ±rla
            retry_min_wait=1,  # Minimum bekleme sÃ¼resini azalt
            cache=False,  # Ã–nbelleÄŸi devre dÄ±ÅŸÄ± bÄ±rak
        )
    
    def _create_agents(self) -> Dict[str, Any]:
        """TÃ¼m agent'larÄ± oluÅŸtur"""
        return {
            AgentType.DATA: self._create_data_agent(),
            AgentType.CAUSAL: self._create_causal_agent(),
            AgentType.QA: self._create_qa_agent()
        }
    
    def _calculate_basic_stats(self, data: pd.Series) -> Dict[str, float]:
        """Temel istatistikleri hesapla"""
        stats = {
            'mean': data.mean(),
            'median': data.median(),
            'std': data.std(),
            'min': data.min(),
            'max': data.max(),
            'q1': data.quantile(0.25),
            'q3': data.quantile(0.75),
            'iqr': data.quantile(0.75) - data.quantile(0.25),
            'skewness': data.skew(),
            'kurtosis': data.kurtosis()
        }
        
        # Varyasyon katsayÄ±sÄ±
        stats['cv'] = (stats['std'] / stats['mean']) * 100 if stats['mean'] != 0 else 0
        
        # Z-skorlarÄ± hesapla
        z_scores = (data - stats['mean']) / stats['std']
        stats['outliers'] = data[abs(z_scores) > 2].to_dict()
        
        # YÃ¼zdelik dilimler
        stats['percentiles'] = {
            'p5': data.quantile(0.05),
            'p10': data.quantile(0.10),
            'p25': data.quantile(0.25),
            'p75': data.quantile(0.75),
            'p90': data.quantile(0.90),
            'p95': data.quantile(0.95)
        }
        
        # DaÄŸÄ±lÄ±m Ã¶zellikleri
        stats['distribution'] = {
            'normality': 'simetrik' if abs(stats['skewness']) < 0.5 else ('saÄŸa Ã§arpÄ±k' if stats['skewness'] > 0 else 'sola Ã§arpÄ±k'),
            'peakedness': 'normal' if abs(stats['kurtosis']) < 0.5 else ('sivri' if stats['kurtosis'] > 0 else 'basÄ±k')
        }
        
        return stats
    
    def _calculate_trend_analysis(self, data: pd.DataFrame, metric: str) -> Dict[str, Any]:
        """Trend analizi yap"""
        yearly_data = data.groupby('year')[metric].agg(['mean', 'std', 'count']).reset_index()
        
        # YÄ±llÄ±k deÄŸiÅŸim oranlarÄ±
        yearly_data['change'] = yearly_data['mean'].pct_change()
        
        # CAGR hesapla
        years = len(yearly_data)
        if years > 1:
            cagr = ((yearly_data['mean'].iloc[-1] / yearly_data['mean'].iloc[0]) ** (1/(years-1)) - 1) * 100
        else:
            cagr = 0
            
        # Volatilite analizi
        volatility = {
            'std_dev': yearly_data['change'].std() * 100,
            'max_drawdown': yearly_data['change'].min() * 100,
            'max_increase': yearly_data['change'].max() * 100
        }
        
        # Trend analizi
        X = np.arange(len(yearly_data)).reshape(-1, 1)
        y = yearly_data['mean'].values
        trend_model = LinearRegression().fit(X, y)
        trend_direction = 'artÄ±ÅŸ' if trend_model.coef_[0] > 0 else 'dÃ¼ÅŸÃ¼ÅŸ'
        trend_strength = trend_model.score(X, y)  # R-kare
        
        return {
            'yearly_stats': yearly_data.to_dict('records'),
            'cagr': cagr,
            'volatility': volatility,
            'trend': {
                'direction': trend_direction,
                'strength': trend_strength,
                'slope': float(trend_model.coef_[0])
            }
        }
    
    def _calculate_comparative_analysis(self, data: pd.DataFrame, metric: str, year: int = None) -> Dict[str, Any]:
        """KarÅŸÄ±laÅŸtÄ±rmalÄ± analiz yap"""
        if year is None:
            year = data['year'].max()
            
        year_data = data[data['year'] == year]
        
        # BÃ¶lgesel analiz
        regional_stats = year_data.groupby('regional_indicator')[metric].agg([
            'mean', 'std', 'count', 'min', 'max', 'median',
            lambda x: x.quantile(0.25),
            lambda x: x.quantile(0.75)
        ]).round(3)
        regional_stats.columns = ['mean', 'std', 'count', 'min', 'max', 'median', 'q1', 'q3']
        
        # Z-skorlarÄ± hesapla
        regional_stats['z_score'] = (regional_stats['mean'] - regional_stats['mean'].mean()) / regional_stats['mean'].std()
        
        # BÃ¶lgesel karÅŸÄ±laÅŸtÄ±rmalar
        global_mean = year_data[metric].mean()
        regional_stats['vs_global'] = ((regional_stats['mean'] - global_mean) / global_mean * 100).round(2)
        
        # BÃ¶lgesel eÅŸitsizlik gÃ¶stergeleri
        regional_stats['gini'] = year_data.groupby('regional_indicator').apply(lambda x: (x[metric].sort_values().reset_index(drop=True) * pd.Series(range(len(x)), index=x[metric].sort_values().index)).sum() / (len(x) * x[metric].sum()) - (len(x) + 1) / (2 * len(x)))
        
        # En iyi/kÃ¶tÃ¼ Ã¼lkeler (bÃ¶lgesel)
        top_by_region = {}
        bottom_by_region = {}
        trends_by_region = {}
        
        for region in regional_stats.index:
            region_data = year_data[year_data['regional_indicator'] == region]
            top_by_region[region] = region_data.nlargest(3, metric)[['country_name', metric]].to_dict('records')
            bottom_by_region[region] = region_data.nsmallest(3, metric)[['country_name', metric]].to_dict('records')
            
            # BÃ¶lgesel trendler
            region_trend = data[data['regional_indicator'] == region].groupby('year')[metric].mean()
            trends_by_region[region] = {
                'growth_rate': ((region_trend.iloc[-1] / region_trend.iloc[0]) - 1) * 100,
                'volatility': region_trend.std() / region_trend.mean() * 100
            }
        
        return {
            'regional_stats': regional_stats.to_dict('index'),
            'global_stats': {
                'mean': global_mean,
                'std': year_data[metric].std(),
                'cv': (year_data[metric].std() / global_mean * 100),
                'range': year_data[metric].max() - year_data[metric].min()
            },
            'top_by_region': top_by_region,
            'bottom_by_region': bottom_by_region,
            'trends_by_region': trends_by_region,
            'outliers': year_data[abs((year_data[metric] - global_mean) / year_data[metric].std()) > 2][
                ['country_name', metric, 'regional_indicator']
            ].to_dict('records')
        }
    
    def _calculate_factor_analysis(self, data: pd.DataFrame, target: str = 'life_ladder') -> Dict[str, Any]:
        """FaktÃ¶r analizi yap"""
        # FaktÃ¶r listesi
        factors = ['social_support', 'freedom_to_make_life_choices', 'generosity', 
                  'perceptions_of_corruption', 'gdp_per_capita', 'life_expectancy']
        
        # Korelasyon analizleri
        correlations = {}
        for factor in factors:
            if factor in data.columns:
                # Pearson korelasyonu
                pearson_corr = data[factor].corr(data[target])
                # Spearman korelasyonu
                spearman_corr = data[factor].corr(data[target], method='spearman')
                
                correlations[factor] = {
                    'pearson': pearson_corr,
                    'spearman': spearman_corr
                }
        
        # Ã‡oklu regresyon
        valid_factors = [f for f in factors if f in data.columns]
        if valid_factors:
            X = data[valid_factors]
            y = data[target]
            model = LinearRegression()
            model.fit(X, y)
            
            regression_results = {
                'r2': model.score(X, y),
                'coefficients': dict(zip(valid_factors, model.coef_)),
                'importance': dict(zip(
                    valid_factors,
                    np.abs(model.coef_) * np.std(X, axis=0)
                ))
            }
        else:
            regression_results = None
        
        # FaktÃ¶r etkileÅŸimleri
        interactions = {}
        for i, f1 in enumerate(valid_factors):
            for f2 in valid_factors[i+1:]:
                interaction_term = data[f1] * data[f2]
                corr_with_target = interaction_term.corr(data[target])
                interactions[f"{f1} x {f2}"] = corr_with_target
        
        return {
            'correlations': correlations,
            'regression': regression_results,
            'interactions': dict(sorted(interactions.items(), key=lambda x: abs(x[1]), reverse=True))
        }
    
    def _create_visualizations(self, data: pd.DataFrame, analysis_type: str, metric: str = None) -> Dict[str, Any]:
        """Analiz tipine gÃ¶re gÃ¶rselleÅŸtirmeler oluÅŸtur"""
        visuals = {}
        
        if analysis_type == "trend":
            # MENA bÃ¶lgesi iÃ§in trend grafiÄŸi
            if metric == 'life_ladder':
                mena_data = data[data['regional_indicator'] == 'Middle East and North Africa']
                yearly_mena = mena_data.groupby('year')['life_ladder'].agg(['mean', 'std']).reset_index()
                
                fig = go.Figure()
                
                # MENA bÃ¶lgesi trend Ã§izgisi
                fig.add_trace(go.Scatter(
                    x=yearly_mena['year'],
                    y=yearly_mena['mean'],
                    mode='lines+markers',
                    name='MENA BÃ¶lgesi',
                    line=dict(color='#8dd3c7', width=3),
                    marker=dict(size=8)
                ))
                
                # Standart sapma aralÄ±ÄŸÄ±
                fig.add_trace(go.Scatter(
                    x=yearly_mena['year'],
                    y=yearly_mena['mean'] + yearly_mena['std'],
                    mode='lines',
                    line=dict(width=0),
                    showlegend=False,
                    name='Ãœst SÄ±nÄ±r'
                ))
                
                fig.add_trace(go.Scatter(
                    x=yearly_mena['year'],
                    y=yearly_mena['mean'] - yearly_mena['std'],
                    mode='lines',
                    line=dict(width=0),
                    fillcolor='rgba(141, 211, 199, 0.3)',
                    fill='tonexty',
                    showlegend=False,
                    name='Alt SÄ±nÄ±r'
                ))
                
                # Global ortalama trend Ã§izgisi
                yearly_global = data.groupby('year')['life_ladder'].mean().reset_index()
                fig.add_trace(go.Scatter(
                    x=yearly_global['year'],
                    y=yearly_global['life_ladder'],
                    mode='lines',
                    name='Global Ortalama',
                    line=dict(color='#bebada', width=2, dash='dash')
                ))
                
                fig.update_layout(
                    title='MENA BÃ¶lgesi Mutluluk Trendi',
                    xaxis_title='YÄ±l',
                    yaxis_title='Mutluluk Skoru',
                    template='plotly_dark',
                    plot_bgcolor='rgba(0,0,0,0)',
                    paper_bgcolor='rgba(0,0,0,0)',
                    hovermode='x unified',
                    legend=dict(
                        yanchor="top",
                        y=0.99,
                        xanchor="left",
                        x=0.01,
                        bgcolor='rgba(0,0,0,0.5)'
                    )
                )
                
                visuals['trend'] = fig
            else:
                # DiÄŸer metrikler iÃ§in genel trend grafiÄŸi
                yearly_data = data.groupby('year')[metric].mean().reset_index()
                
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=yearly_data['year'],
                    y=yearly_data[metric],
                    mode='lines+markers',
                    name=metric,
                    line=dict(color='#8dd3c7', width=3)
                ))
                
                fig.update_layout(
                    title=f"{metric.replace('_', ' ').title()} Trend Analysis",
                    xaxis_title="Year",
                    yaxis_title=metric.replace('_', ' ').title(),
                    template="plotly_dark"
                )
                
                visuals['trend'] = fig
            
        elif analysis_type == "comparison":
            # BÃ¶lgesel karÅŸÄ±laÅŸtÄ±rma grafiÄŸi
            latest_year = data['year'].max()
            latest_data = data[data['year'] == latest_year]
            
            fig = px.box(
                latest_data,
                x='regional_indicator',
                y=metric,
                title=f"Regional Comparison of {metric.replace('_', ' ').title()}",
                template="plotly_dark"
            )
            
            visuals['comparison'] = fig
            
        elif analysis_type == "correlation":
            # Korelasyon matrisi
            factors = ['life_ladder', 'gdp_per_capita', 'social_support', 
                      'freedom_to_make_life_choices', 'generosity', 
                      'perceptions_of_corruption']
            
            corr_matrix = data[factors].corr()
            
            fig = px.imshow(
                corr_matrix,
                labels=dict(color="Correlation"),
                x=[f.replace('_', ' ').title() for f in factors],
                y=[f.replace('_', ' ').title() for f in factors],
                title="Correlation Matrix",
                template="plotly_dark"
            )
            
            visuals['correlation'] = fig
            
        elif analysis_type == "causal":
            # Nedensel aÄŸ grafiÄŸi
            factors = ['gdp_per_capita', 'social_support', 'freedom_to_make_life_choices',
                      'generosity', 'perceptions_of_corruption']
            
            # FaktÃ¶rler arasÄ± korelasyonlarÄ± hesapla
            correlations = []
            for i, f1 in enumerate(factors):
                for f2 in factors[i+1:]:
                    corr = data[f1].corr(data[f2])
                    if abs(corr) > 0.3:  # Sadece Ã¶nemli korelasyonlarÄ± gÃ¶ster
                        correlations.append((f1, f2, corr))
            
            # Nedensel aÄŸ grafiÄŸi oluÅŸtur
            fig = go.Figure()
            
            # DÃ¼ÄŸÃ¼mleri ekle
            for i, factor in enumerate(factors):
                fig.add_trace(go.Scatter(
                    x=[i],
                    y=[0],
                    mode='markers+text',
                    name=factor,
                    text=[factor.replace('_', ' ').title()],
                    marker=dict(size=20),
                    textposition="bottom center"
                ))
            
            # BaÄŸlantÄ±larÄ± ekle
            for f1, f2, corr in correlations:
                i1 = factors.index(f1)
                i2 = factors.index(f2)
                
                fig.add_trace(go.Scatter(
                    x=[i1, i2],
                    y=[0, 0],
                    mode='lines',
                    line=dict(
                        width=abs(corr) * 5,
                        color='red' if corr < 0 else 'green'
                    ),
                    name=f"{f1} - {f2} ({corr:.2f})"
                ))
            
            fig.update_layout(
                title="Causal Network Graph",
                showlegend=False,
                template="plotly_dark"
            )
            
            visuals['causal'] = fig
        
        return visuals
    
    def _format_analysis_results(self, results: Dict[str, Any]) -> str:
        """Analiz sonuÃ§larÄ±nÄ± formatla ve gÃ¶rselleÅŸtir"""
        output = []
        
        # Temel Analiz
        output.append("## ğŸ“Š Temel Bulgular")
        stats = results.get('basic_stats', {})
        if stats:
            output.append("\n### ğŸ“ˆ Ä°statistiksel Ã–zet")
            output.append(f"- **Ortalama:** {stats.get('mean', 0):.2f}")
            output.append(f"- **Medyan:** {stats.get('median', 0):.2f}")
            output.append(f"- **Standart Sapma:** {stats.get('std', 0):.2f}")
            output.append(f"- **DeÄŸiÅŸim AralÄ±ÄŸÄ±:** {stats.get('min', 0):.2f} - {stats.get('max', 0):.2f}")
            
            # DaÄŸÄ±lÄ±m Ã¶zellikleri
            dist = stats.get('distribution', {})
            if dist:
                output.append("\n### ğŸ“Š DaÄŸÄ±lÄ±m Analizi")
                output.append(f"- **DaÄŸÄ±lÄ±m Tipi:** {dist.get('normality', 'bilinmiyor')}")
                output.append(f"- **Tepe NoktasÄ±:** {dist.get('peakedness', 'bilinmiyor')}")
                output.append(f"- **DeÄŸiÅŸkenlik KatsayÄ±sÄ±:** %{stats.get('cv', 0):.1f}")
        
        # BÃ¶lgesel Analiz
        comp_analysis = results.get('comparative_analysis', {})
        if comp_analysis:
            output.append("\n## ğŸŒ BÃ¶lgesel KarÅŸÄ±laÅŸtÄ±rma")
            
            # Global istatistikler
            global_stats = comp_analysis.get('global_stats', {})
            output.append("\n### ğŸŒ Global Durum")
            output.append(f"- **Global Ortalama:** {global_stats.get('mean', 0):.2f}")
            output.append(f"- **Global DeÄŸiÅŸkenlik:** %{global_stats.get('cv', 0):.1f}")
            
            # BÃ¶lgesel sÄ±ralama
            regional_stats = comp_analysis.get('regional_stats', {})
            if regional_stats:
                output.append("\n### ğŸ“Š BÃ¶lgesel SÄ±ralama")
                sorted_regions = sorted(
                    regional_stats.items(),
                    key=lambda x: x[1]['mean'],
                    reverse=True
                )
                
                # BÃ¶lgesel karÅŸÄ±laÅŸtÄ±rma grafiÄŸi
                fig = go.Figure()
                
                regions = [region for region, _ in sorted_regions]
                means = [stats['mean'] for _, stats in sorted_regions]
                stds = [stats['std'] for _, stats in sorted_regions]
                
                # Bar grafiÄŸi
                fig.add_trace(go.Bar(
                    x=regions,
                    y=means,
                    error_y=dict(type='data', array=stds),
                    name='Ortalama DeÄŸer',
                    marker_color='#8dd3c7'
                ))
                
                fig.update_layout(
                    title='BÃ¶lgelere GÃ¶re KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz',
                    xaxis_title="BÃ¶lge",
                    yaxis_title="DeÄŸer",
                    template="plotly_dark",
                    plot_bgcolor='rgba(0,0,0,0)',
                    paper_bgcolor='rgba(0,0,0,0)',
                    xaxis=dict(tickangle=-45),
                    showlegend=False,
                    height=500
                )
                
                # GrafiÄŸi doÄŸrudan gÃ¶ster
                st.plotly_chart(fig, use_container_width=True)
                
                # Metin olarak da gÃ¶ster
                for region, stats in sorted_regions[:3]:
                    output.append(f"\n**{region}**")
                    output.append(f"- Ortalama: {stats['mean']:.2f}")
                    output.append(f"- DeÄŸiÅŸkenlik: %{stats['std']/stats['mean']*100:.1f}")
                    output.append(f"- Gini KatsayÄ±sÄ±: {stats.get('gini', 0):.3f}")
        
        # Trend Analizi
        trends = results.get('trends_by_region', {})
        if trends:
            output.append("\n## ğŸ“ˆ Trend Analizi")
            
            # En yÃ¼ksek bÃ¼yÃ¼me gÃ¶steren bÃ¶lgeler
            sorted_growth = sorted(
                [(region, data['growth_rate']) for region, data in trends.items()],
                key=lambda x: x[1],
                reverse=True
            )
            
            output.append("\n### ğŸš€ BÃ¼yÃ¼me PerformansÄ±")
            for region, growth in sorted_growth[:3]:
                output.append(f"- **{region}:** %{growth:.1f} bÃ¼yÃ¼me")
        
        # GÃ¶rselleÅŸtirmeleri ekle
        output.append("\n## ğŸ“Š GÃ¶rsel Analizler")
        
        # Trend grafiÄŸi
        visuals = self._create_visualizations(self.df, "trend", results.get('metric'))
        if visuals.get('trend'):
            output.append("\n### ğŸ“ˆ Trend Analizi")
            st.plotly_chart(visuals['trend'], use_container_width=True)
        
        # BÃ¶lgesel karÅŸÄ±laÅŸtÄ±rma
        visuals = self._create_visualizations(self.df, "comparison", results.get('metric'))
        if visuals.get('comparison'):
            output.append("\n### ğŸ“Š BÃ¶lgesel KarÅŸÄ±laÅŸtÄ±rma")
            st.plotly_chart(visuals['comparison'], use_container_width=True)
        
        # Korelasyon matrisi
        visuals = self._create_visualizations(self.df, "correlation")
        if visuals.get('correlation'):
            output.append("\n### ğŸ” Korelasyon Analizi")
            st.plotly_chart(visuals['correlation'], use_container_width=True)
        
        # Nedensel aÄŸ grafiÄŸi
        if results.get('agent_type') == AgentType.CAUSAL:
            visuals = self._create_visualizations(self.df, "causal")
            if visuals.get('causal'):
                output.append("\n### ğŸ”„ Nedensel Ä°liÅŸkiler")
                st.plotly_chart(visuals['causal'], use_container_width=True)
        
        # Ä°Ã§gÃ¶rÃ¼ler
        if results.get('insights'):
            output.append("\n## ğŸ” Ã–nemli Ä°Ã§gÃ¶rÃ¼ler")
            for i, insight in enumerate(results['insights'], 1):
                output.append(f"\n{i}. {insight}")
        
        # Metodoloji
        if results.get('methodology'):
            output.append("\n## â„¹ï¸ Metodoloji NotlarÄ±")
            for note in results['methodology']:
                output.append(f"- {note}")
        
        return "\n".join(output)
    
    def _create_data_agent(self) -> LLMChain:
        """Veri analizi agent'Ä±"""
        # Veri setinden temel istatistikleri hesapla
        latest_year = self.df['year'].max()
        latest_data = self.df[self.df['year'] == latest_year]
        
        # Veri seti Ã¶zeti oluÅŸtur
        data_summary = {
            'total_countries': len(latest_data['country_name'].unique()),
            'year_range': f"{self.df['year'].min()} - {self.df['year'].max()}",
            'available_metrics': list(self.df.columns),
            'regions': list(latest_data['regional_indicator'].unique()),
            'global_happiness_mean': latest_data['life_ladder'].mean(),
            'happiest_country': latest_data.nlargest(1, 'life_ladder')['country_name'].iloc[0],
            'unhappiest_country': latest_data.nsmallest(1, 'life_ladder')['country_name'].iloc[0]
        }
        
        # Prompt template'i gÃ¼ncelle
        template = """Sen deneyimli bir veri bilimci ve ekonomist olarak, verilen veri setini kullanarak kapsamlÄ± ve gÃ¶rsel analizler yapacaksÄ±n.

VERÄ° SETÄ° HAKKINDA:
- Toplam Ãœlke SayÄ±sÄ±: {total_countries}
- YÄ±l AralÄ±ÄŸÄ±: {year_range}
- Mevcut Metrikler: {metrics}
- BÃ¶lgeler: {regions}
- Global Mutluluk OrtalamasÄ±: {global_mean:.2f}
- En Mutlu Ãœlke: {happiest}
- En Mutsuz Ãœlke: {unhappiest}

TEMEL PRENSÄ°PLER:

1. VERÄ° ANALÄ°ZÄ°
   - Temel istatistikler ve daÄŸÄ±lÄ±mlar
   - Trend ve deÄŸiÅŸim analizleri
   - BÃ¶lgesel karÅŸÄ±laÅŸtÄ±rmalar
   - FaktÃ¶r iliÅŸkileri
   - GÃ¶rsel analizler

2. Ä°Ã‡GÃ–RÃœ GELÄ°ÅTÄ°RME
   - Ã–nemli bulgularÄ± vurgula
   - Nedensel iliÅŸkileri aÃ§Ä±kla
   - KarÅŸÄ±laÅŸtÄ±rmalÄ± deÄŸerlendirmeler yap
   - Politika Ã¶nerileri geliÅŸtir
   - Gelecek projeksiyonlarÄ± sun

3. GÃ–RSEL SUNUM
   - Trend grafikleri [Trend: metrik]
   - KarÅŸÄ±laÅŸtÄ±rma grafikleri [Bar: metrik]
   - Korelasyon matrisleri [Scatter: metrik1 vs metrik2]
   - DaÄŸÄ±lÄ±m grafikleri

4. RAPORLAMA YAPISI
   ğŸ“Š Temel Bulgular
      - Ã–nemli metrikler
      - Kritik deÄŸiÅŸimler
      - AykÄ±rÄ± deÄŸerler

   ğŸ“ˆ Trend Analizi
      - Zaman serisi deÄŸiÅŸimleri
      - BÃ¼yÃ¼me oranlarÄ±
      - Volatilite analizi

   ğŸŒ KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz
      - BÃ¶lgesel farklÄ±lÄ±klar
      - Lider ve geride kalan Ã¼lkeler
      - BaÅŸarÄ± faktÃ¶rleri

   ğŸ” FaktÃ¶r Analizi
      - Korelasyonlar
      - Nedensel iliÅŸkiler
      - EtkileÅŸim etkileri

   ğŸ’¡ Ã–neriler ve Projeksiyonlar
      - Politika Ã¶nerileri
      - Ä°yileÅŸtirme alanlarÄ±
      - Gelecek tahminleri

Soru: {question}

YanÄ±tÄ±nÄ± verirken mutlaka veri setindeki gerÃ§ek deÄŸerleri kullan ve gÃ¶rsellerle destekle. Her sayÄ±sal deÄŸer ve trend veri setinden gelmeli."""

        prompt = PromptTemplate(
            template=template,
            input_variables=["question"],
            partial_variables={
                "total_countries": str(data_summary['total_countries']),
                "year_range": data_summary['year_range'],
                "metrics": ", ".join(data_summary['available_metrics']),
                "regions": ", ".join(data_summary['regions']),
                "global_mean": data_summary['global_happiness_mean'],
                "happiest": data_summary['happiest_country'],
                "unhappiest": data_summary['unhappiest_country']
            }
        )
        return LLMChain(llm=self.llm, prompt=prompt)
    
    def _create_causal_agent(self) -> LLMChain:
        """Nedensel analiz agent'Ä±"""
        variables = list(self.df.columns)
        
        # Sistem mesajÄ±nÄ± ve kullanÄ±cÄ± template'ini ayÄ±r
        system_message = """Sen bir sosyal bilimci ve mutluluk araÅŸtÄ±rmacÄ±sÄ±sÄ±n. 
GÃ¶revin, spesifik Ã¼lke veya bÃ¶lgelerin mutluluk durumunu analiz etmek.
YanÄ±tlarÄ±n MUTLAKA ÅŸu yapÄ±da olmalÄ±:

1. MEVCUT DURUM
2. BAÅARI/BAÅARISIZLIK NEDENLERÄ°
3. Ã–NEMLÄ° DETAYLAR

Genel istatistikler veya korelasyonlar yerine, 
sorulan Ã¼lke/bÃ¶lgeye Ã¶zel veriler ve analizler sunmalÄ±sÄ±n."""
        
        # Daha katÄ± bir template yapÄ±sÄ±
        template = """YANITINI KESÄ°NLÄ°KLE BU FORMATTA VER:

ğŸ¯ MEVCUT DURUM:
- {Ã¼lke/bÃ¶lge} gÃ¼ncel mutluluk skoru: [DEÄER]
- DÃ¼nya sÄ±ralamasÄ±ndaki yeri: [SIRA]
- Ã–ne Ã§Ä±kan faktÃ¶rler: [FAKTÃ–RLER]

ğŸ“ˆ BAÅARI/BAÅARISIZLIK NEDENLERÄ°:
1. [Ä°LK FAKTÃ–R]
   - Veri: [DEÄER]
   - KarÅŸÄ±laÅŸtÄ±rma: [KARÅILAÅTIRMA]

2. [Ä°KÄ°NCÄ° FAKTÃ–R]
   - Veri: [DEÄER]
   - KarÅŸÄ±laÅŸtÄ±rma: [KARÅILAÅTIRMA]

ğŸ’¡ Ã–NEMLÄ° DETAYLAR:
- [DETAY 1]
- [DETAY 2]
- [DETAY 3]

Veri setindeki deÄŸiÅŸkenler: {variables}
Soru: {question}"""
        
        prompt = PromptTemplate(
            template=template,
            input_variables=["question", "variables"]
        )
        
        # LLM'i daha katÄ± ayarlarla yapÄ±landÄ±r
        llm = ChatGoogleGenerativeAI(
            model="gemini-pro",
            temperature=0,  # YaratÄ±cÄ±lÄ±ÄŸÄ± minimumda tut
            google_api_key=GOOGLE_API_KEY,
            convert_system_message_to_human=True,  # Sistem mesajÄ±nÄ± insan mesajÄ±na Ã§evir
            max_output_tokens=2048,
            top_p=0.1,  # Daha deterministik yanÄ±tlar
            top_k=1,    # En olasÄ± yanÄ±tÄ± seÃ§
        )
        
        return LLMChain(
            llm=llm,
            prompt=prompt,
            verbose=True  # Debug iÃ§in
        )
    
    def _create_qa_agent(self) -> LLMChain:
        """Genel soru-cevap agent'Ä±"""
        prompt = PromptTemplate(
            template=GENERAL_QA_TEMPLATE,
            input_variables=["question"]
        )
        return LLMChain(llm=self.llm, prompt=prompt)

    def route_question(self, question: str) -> str:
        """Soruyu uygun agent'a yÃ¶nlendir"""
        # KÃ¼Ã§Ã¼k harfe Ã§evir ve noktalama iÅŸaretlerini kaldÄ±r
        question_lower = ''.join(c.lower() for c in question if c.isalnum() or c.isspace())
        words = question_lower.split()
        
        # Nedensel analiz iÃ§in spesifik kalÄ±plar
        causal_patterns = [
            "neden bu kadar",
            "niye bu kadar",
            "niÃ§in bu kadar",
            "neden bu denli",
            "neden bÃ¶yle",
            "niye bÃ¶yle",
            "nasÄ±l bu kadar",
            "sebebi ne",
            "nedeni ne"
        ]
        
        # Veri analizi iÃ§in spesifik kalÄ±plar
        data_patterns = [
            "kaÃ§ tane",
            "ne kadar",
            "hangi Ã¼lke",
            "hangi bÃ¶lge",
            "en mutlu",
            "en mutsuz",
            "karÅŸÄ±laÅŸtÄ±r",
            "kÄ±yasla",
            "sÄ±rala",
            "gÃ¶ster",
            "trend",
            "deÄŸiÅŸim",
            "analiz",
            "fark",
            "arasÄ±nda"
        ]
        
        # Ã–nce nedensel analiz kalÄ±plarÄ±nÄ± kontrol et
        for pattern in causal_patterns:
            if pattern in question_lower:
                return AgentType.CAUSAL
        
        # Sonra veri analizi kalÄ±plarÄ±nÄ± kontrol et
        for pattern in data_patterns:
            if pattern in question_lower:
                return AgentType.DATA
        
        # EÄŸer hiÃ§bir spesifik kalÄ±p eÅŸleÅŸmezse, QA'ya yÃ¶nlendir
        return AgentType.QA

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=1, max=10),
        reraise=True
    )
    async def _get_llm_response(self, agent: Any, **kwargs) -> str:
        """LLM yanÄ±tlarÄ±nÄ± yÃ¶net ve gÃ¶rselleÅŸtirmeleri iÅŸle"""
        try:
            # LLM yanÄ±tÄ±nÄ± al
            response = await agent.ainvoke(kwargs)
            
            # YanÄ±t kontrolÃ¼
            if not response or 'text' not in response:
                raise ValueError("LLM'den geÃ§erli bir yanÄ±t alÄ±namadÄ±")
                
            response_text = response['text']
            
            if not response_text or not isinstance(response_text, str):
                raise ValueError("LLM yanÄ±tÄ± boÅŸ veya geÃ§ersiz format")

            # Format kontrolÃ¼ (Causal agent iÃ§in)
            if isinstance(agent, LLMChain) and 'CAUSAL_ANALYSIS_TEMPLATE' in str(agent.prompt):
                # Ãœlke/bÃ¶lge adÄ±nÄ± Ã§Ä±kar
                country_match = re.search(r'ğŸ¯\s*\[([^\]]+)\]', response_text)
                country_name = country_match.group(1) if country_match else "Ä°lgili Ãœlke/BÃ¶lge"
                
                # YanÄ±tÄ± yeniden formatla
                if not any(section in response_text for section in ['ANALÄ°ZÄ°:', 'HÄ°KAYESÄ°:', 'BAKIÅ:']):
                    formatted_response = f"ğŸ¯ [{country_name}] ANALÄ°ZÄ°:\n"
                    formatted_response += "- GÃ¼ncel durum analizi yapÄ±lÄ±yor...\n\n"
                    formatted_response += "ğŸ“ˆ BAÅARI/BAÅARISIZLIK HÄ°KAYESÄ°:\n"
                    formatted_response += response_text + "\n\n"
                    formatted_response += "ğŸ’¡ KARÅILAÅTIRMALI BAKIÅ:\n"
                    formatted_response += "- KarÅŸÄ±laÅŸtÄ±rmalÄ± analiz devam ediyor...\n"
                    
                    response_text = formatted_response

            # GÃ¶rsel referanslarÄ±nÄ± iÅŸle
            try:
                processed_response = self._process_visualizations(response_text)
            except Exception as e:
                st.warning(f"GÃ¶rselleÅŸtirmeler iÅŸlenirken bazÄ± hatalar oluÅŸtu. Analiz devam ediyor.")
                processed_response = response_text
            
            return processed_response

        except Exception as e:
            st.error(f"LLM yanÄ±tÄ± alÄ±nÄ±rken hata: {str(e)}")
            return "YanÄ±t alÄ±namadÄ±. LÃ¼tfen tekrar deneyin."

    def _process_visualizations(self, response: str) -> str:
        """LLM yanÄ±tÄ±ndaki gÃ¶rsel referanslarÄ±nÄ± gerÃ§ek grafiklere dÃ¶nÃ¼ÅŸtÃ¼r"""
        try:
            # YanÄ±t kontrolÃ¼
            if not response or not isinstance(response, str):
                return response

            # KÃ¶ÅŸeli parantez iÃ§indeki gÃ¶rsel referanslarÄ±nÄ± bul
            visual_refs = re.finditer(r'\[([^]]+)\]', response)
            
            for match in visual_refs:
                try:
                    visual_desc = match.group(1).strip().lower()
                    
                    # GÃ¶rsel tipi ve metrik iÃ§in varsayÄ±lan deÄŸerler
                    visual_type = None
                    metric = 'life_ladder'
                    metric2 = None
                    countries = []
                    
                    # GÃ¶rsel tipini belirle
                    if any(keyword in visual_desc for keyword in ['trend', 'deÄŸiÅŸim', 'zaman']):
                        visual_type = 'trend'
                    elif any(keyword in visual_desc for keyword in ['bar', 'karÅŸÄ±laÅŸtÄ±rma', 'sÃ¼tun']):
                        visual_type = 'bar'
                    elif any(keyword in visual_desc for keyword in ['saÃ§Ä±lÄ±m', 'korelasyon', 'iliÅŸki']):
                        visual_type = 'scatter'
                    
                    # Metrikleri belirle
                    metric_mapping = {
                        'gsyih': 'gdp_per_capita',
                        'gdp': 'gdp_per_capita',
                        'mutluluk': 'life_ladder',
                        'puan': 'life_ladder',
                        'skor': 'life_ladder',
                        'sosyal destek': 'social_support',
                        'Ã¶zgÃ¼rlÃ¼k': 'freedom_to_make_life_choices',
                        'yolsuzluk': 'perceptions_of_corruption',
                        'cÃ¶mertlik': 'generosity',
                        'yaÅŸam beklentisi': 'life_expectancy',
                        'internet': 'internet_users_percent'
                    }
                    
                    # Metrikleri tespit et
                    for keyword, col in metric_mapping.items():
                        if keyword in visual_desc:
                            if metric == 'life_ladder':
                                metric = col
                            else:
                                metric2 = col
                                break
                    
                    # Ãœlkeleri belirle
                    country_mapping = {
                        'tÃ¼rkiye': 'Turkiye',
                        'kolombiya': 'Colombia',
                        'amerika': 'United States',
                        'abd': 'United States'
                    }
                    
                    for keyword, country in country_mapping.items():
                        if keyword in visual_desc:
                            countries.append(country)
                    
                    # Veri kontrolÃ¼
                    if not self.df[self.df['country_name'].isin(countries)].empty:
                        latest_year = self.df['year'].max()
                        
                        if visual_type == 'scatter':
                            latest_data = self.df[self.df['year'] == latest_year].copy()
                            
                            # Metrik kontrolÃ¼
                            if metric not in latest_data.columns or (metric2 and metric2 not in latest_data.columns):
                                st.warning(f"BazÄ± metrikler veri setinde bulunamadÄ±: {metric}, {metric2}")
                                continue
                            
                            fig = go.Figure()
                            fig.add_trace(go.Scatter(
                                x=latest_data[metric],
                                y=latest_data[metric2] if metric2 else latest_data['life_ladder'],
                                mode='markers',
                                marker=dict(
                                    size=10,
                                    color=latest_data['regional_indicator'].astype('category').cat.codes,
                                    colorscale='Viridis',
                                    showscale=True
                                ),
                                text=latest_data['country_name'],
                                hovertemplate='<b>%{text}</b><br>' +
                                            f'{metric}: %{{x}}<br>' +
                                            f'{metric2 if metric2 else "life_ladder"}: %{{y}}<br>'
                            ))
                            
                            fig.update_layout(
                                title=f"{metric.replace('_', ' ').title()} ve {(metric2 if metric2 else 'Mutluluk')} Ä°liÅŸkisi",
                                xaxis_title=metric.replace('_', ' ').title(),
                                yaxis_title=metric2.replace('_', ' ').title() if metric2 else 'Mutluluk Skoru',
                                template='plotly_dark',
                                plot_bgcolor='rgba(0,0,0,0)',
                                paper_bgcolor='rgba(0,0,0,0)'
                            )
                            
                            st.plotly_chart(fig, use_container_width=True)
                            
                        elif visual_type == 'trend':
                            if countries:
                                country_data = self.df[self.df['country_name'].isin(countries)]
                            else:
                                # EÄŸer Ã¼lke belirtilmemiÅŸse, global trend gÃ¶ster
                                country_data = self.df.groupby('year')[metric].mean().reset_index()
                                countries = ['Global Ortalama']
                            
                            if not country_data.empty:
                                fig = go.Figure()
                                
                                if len(countries) == 1 and countries[0] == 'Global Ortalama':
                                    fig.add_trace(go.Scatter(
                                        x=country_data['year'],
                                        y=country_data[metric],
                                        mode='lines+markers',
                                        name='Global Ortalama',
                                        line=dict(width=3),
                                        marker=dict(size=8)
                                    ))
                                
                                fig.update_layout(
                                    title=f"{''.join(countries)} {metric.replace('_', ' ').title()} Trendi",
                                    xaxis_title='YÄ±l',
                                    yaxis_title=metric.replace('_', ' ').title(),
                                    template='plotly_dark',
                                    plot_bgcolor='rgba(0,0,0,0)',
                                    paper_bgcolor='rgba(0,0,0,0)'
                                )
                                
                                st.plotly_chart(fig, use_container_width=True)
                            
                        elif visual_type == 'bar':
                            latest_data = self.df[self.df['year'] == latest_year].copy()
                            
                            if not latest_data.empty:
                                # Top 10 Ã¼lkeyi seÃ§
                                sorted_data = latest_data.nlargest(10, metric)
                                
                                fig = go.Figure()
                                fig.add_trace(go.Bar(
                                    x=sorted_data['country_name'],
                                    y=sorted_data[metric],
                                    marker_color=['#8dd3c7' if x in countries else '#bebada' for x in sorted_data['country_name']],
                                    text=sorted_data[metric].round(2),
                                    textposition='auto'
                                ))
                                
                                fig.update_layout(
                                    title=f"En YÃ¼ksek {metric.replace('_', ' ').title()} DeÄŸerine Sahip 10 Ãœlke",
                                    xaxis_title='Ãœlkeler',
                                    yaxis_title=metric.replace('_', ' ').title(),
                                    template='plotly_dark',
                                    plot_bgcolor='rgba(0,0,0,0)',
                                    paper_bgcolor='rgba(0,0,0,0)',
                                    xaxis=dict(tickangle=-45)
                                )
                                
                                st.plotly_chart(fig, use_container_width=True)
                    
                except Exception as e:
                    st.warning(f"Bir gÃ¶rselleÅŸtirme iÅŸlenirken hata oluÅŸtu: {str(e)}")
                    continue
            
            return response

        except Exception as e:
            st.error(f"GÃ¶rselleÅŸtirmeler iÅŸlenirken hata: {str(e)}")
            return response

    @st.cache_data(ttl=3600)  # 1 saat Ã¶nbellek
    def _process_cached_response(self, response: str) -> Dict[str, Any]:
        """YanÄ±tlarÄ± iÅŸle ve Ã¶nbellekle"""
        try:
            # YanÄ±t iÅŸleme mantÄ±ÄŸÄ±
            processed_response = {
                'text': response,
                'timestamp': pd.Timestamp.now()
            }
            return processed_response
        except Exception as e:
            st.error(f"YanÄ±t iÅŸlenirken hata: {str(e)}")
            return None

    async def get_answer(self, question: str) -> str:
        """
        Verilen soruyu uygun agent'a yÃ¶nlendirir ve yanÄ±t alÄ±r.
        """
        try:
            # Soruyu uygun agent'a yÃ¶nlendir
            agent_type = self.route_question(question)
            st.info(f"Soru {agent_type} agent'Ä±na yÃ¶nlendirildi...")
            
            # Soru tipine gÃ¶re Ã¶zel deÄŸiÅŸkenleri hazÄ±rla
            kwargs = {
                'question': question
            }
            
            # Causal agent iÃ§in ek deÄŸiÅŸkenler
            if agent_type == AgentType.CAUSAL:
                kwargs['variables'] = list(self.df.columns)
            
            # Data agent iÃ§in ek deÄŸiÅŸkenler
            elif agent_type == AgentType.DATA:
                metric = self._determine_metric(question)
                if metric:
                    kwargs['metric'] = metric
            
            # LLM yanÄ±tÄ±nÄ± al
            response = await self._get_llm_response(
                self.agents[agent_type],
                **kwargs
            )
            
            # YanÄ±t kontrolÃ¼
            if not response:
                return ""
            
            # YanÄ±tÄ± string'e Ã§evir
            if not isinstance(response, str):
                response = str(response)
            
            return response
            
        except Exception as e:
            st.error(f"YanÄ±t alÄ±nÄ±rken hata oluÅŸtu: {str(e)}")
            return ""

    def _determine_metric(self, question: str) -> Optional[str]:
        """Sorudan metrik belirle"""
        metric_keywords = {
            'sosyal destek': 'social_support',
            'Ã¶zgÃ¼rlÃ¼k': 'freedom_to_make_life_choices',
            'yolsuzluk': 'perceptions_of_corruption',
            'cÃ¶mertlik': 'generosity',
            'gdp': 'gdp_per_capita',
            'yaÅŸam beklentisi': 'life_expectancy',
            'mutluluk': 'life_ladder',
            'skor': 'life_ladder',
            'puan': 'life_ladder',
            'doÄŸum': 'fertility_rate',
            'doÄŸum oranÄ±': 'fertility_rate',
            'fertility': 'fertility_rate'
        }
        
        question_lower = question.lower()
        for keyword, col in metric_keywords.items():
            if keyword in question_lower and col in self.df.columns:
                return col
        
        return None

class ConversationManager:
    def __init__(self):
        self.conversation_history = []
        self.context = {}
    
    def add_to_history(self, question: str, answer: str, agent_type: str):
        """Soru ve cevabÄ± geÃ§miÅŸe ekle"""
        self.conversation_history.append({
            'question': question,
            'answer': answer,
            'agent_type': agent_type,
            'timestamp': pd.Timestamp.now()
        })
    
    def get_relevant_context(self, question: str, max_history: int = 3) -> List[Dict]:
        """Soru ile ilgili geÃ§miÅŸ yanÄ±tlarÄ± bul"""
        # Basit kelime benzerliÄŸi kontrolÃ¼
        question_words = set(question.lower().split())
        
        relevant_history = []
        for entry in reversed(self.conversation_history):
            entry_words = set(entry['question'].lower().split())
            # Kelime kesiÅŸimi oranÄ±
            similarity = len(question_words.intersection(entry_words)) / len(question_words)
            
            if similarity > 0.3:  # En az %30 benzerlik
                relevant_history.append(entry)
                
            if len(relevant_history) >= max_history:
                break
                
        return relevant_history 